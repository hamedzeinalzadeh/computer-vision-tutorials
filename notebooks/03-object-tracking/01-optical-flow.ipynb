{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd12da57-5a66-413d-b40c-174d1603e157",
   "metadata": {},
   "source": [
    "<img src=\"../DATA/corp_logo.jpg\" width='160'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938c390b-e5dd-4b81-843b-06f0cb2264d8",
   "metadata": {},
   "source": [
    "# Optical Flow\n",
    "\n",
    ">#### Note: \n",
    ">**If you are a notebook user it is prefered to shutdown other notebooks' kernels and restart the kernel in this notebook. That is because the tracking algorihtm can sometimes get caught in a loop with your camera.**\n",
    "\n",
    "OPtical flow is the pattern of apparent motion of image objects between two consecutive frames caused by the movement of object or camera (caused by the either movement of objects or camera)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b49e6a3-c3cb-42d9-84fe-b5c910cdfef7",
   "metadata": {},
   "source": [
    "## Assumptions:\n",
    "- The pixel intensities of an object do not change between consecutive frames. (We are not trying to track a lightbulb that is turning off and on as it moves between frames of a video.)\n",
    "- Neibouring pixels have similar motions. (The actual pixels around the point you're trying to track such as the center of light bulb are also moving along). So it's not just some random single point moving.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1688f5f0-e511-43b1-a5e6-f5948c8c60b0",
   "metadata": {},
   "source": [
    ">**Note:**\n",
    "<br>- The optical flow methods in OpenCV will first take in a given set of points and a frame.\n",
    "<br>- then it will attemp to find those points in the next frame.\n",
    "<br>- It is up to the user to supply the points to track."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68341b7d-10ca-4931-b5ad-e3f4a4a80e1c",
   "metadata": {},
   "source": [
    "<img src=\"./images/five_frames_of_ball_0.png\" width= \"500\">\n",
    "The image above, displays a five frame clip of a ball moving up and towards the right. Note that in the optical flow technique, given just this clip, there is no way to determine if the ball is moving, or if the camera moved down and to the left.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<img src=\"./images/five_frames_of_ball_1.png\" width= \"500\">\n",
    "Using OpenCV we pass in the previous frame, previous points and the current frame to the optical flow function named \n",
    "**Lucas-Kanade** function.We are actually trying to track the object from frame 4 to frame 5 (the most recent frame in our video). We would have had to have told Open see what the point we wanted to track (the green point on the frame 4) or more advanced techniques such as object detection).\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<img src=\"./images/five_frames_of_ball_2.png\" width= \"500\">\n",
    "Then we take in the entire previous frame.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<img src=\"./images/five_frames_of_ball_3.png\" width= \"500\">\n",
    "Then we look at our current frame. \n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<img src=\"./images/five_frames_of_ball_4.png\" width= \"500\">\n",
    "What this function attempts to do is locate the points from frame for that we wanted to track and find them in frame 5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4259ee10-5b1d-4113-809d-ac60eb871395",
   "metadata": {},
   "source": [
    ">**Note:**\n",
    "<br>- The Lucas-kanade computes optical flow for a **sparse** (meaning only the points it was told to track) feature set. In other words, it is not suitalbe for cases with purpose of tracking all the points in video."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ec57c6-be5d-47d4-a63a-8aa97d742466",
   "metadata": {},
   "source": [
    "Gunner Farneback's algorithm(also built-in to OpenCV) is used for calculating **dense function** optical flow(calculate flow for all points in an image). It will color them black if no flow(no movement) is detected.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0bc34e-e0c9-486b-a12c-a4c0dd8a397d",
   "metadata": {},
   "source": [
    "## Lucas-Kanade Optical Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87a342aa-bf3e-47ce-8087-cc3acfa37434",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee0fcbe9-ae1f-4b29-ae6e-e83467525da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for ShiTomasi corner detection (good features to track paper)\n",
    "# On the very first frame, detect 10 corners\n",
    "corner_track_params = {\n",
    "    'maxCorners': 10,\n",
    "    'qualityLevel': 0.3,\n",
    "    'minDistance': 7,\n",
    "    'blockSize': 7\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd4e06f-ef63-4d34-be25-26c6923e7ef5",
   "metadata": {},
   "source": [
    "### Parameters for Lucas-Kanade Optical Flow\n",
    "\n",
    "- **winSize:** Detect the motion of specific points or the aggregated motion of regions by modifying the `winSize` argument. This determines the integration window size. Small windows are more sensitive to noise and may miss larger motions. Large windows will “survive” an occlusion and less able to catch smaller motions. The integration appears smoother with the larger window size.\n",
    "\n",
    "- **maxLevel:** When `maxLevel` is 0, it is the same algorithm without using pyramids (ie, calcOpticalFlowLK). Pyramids allow finding optical flow at various resolutions of the image. Check out the link for the [Pyramid image processing](https://en.wikipedia.org/wiki/Pyramid_(image_processing))\n",
    "\n",
    "- **criteria:** Providing two `criteria` to perform Lucas-Kanade Optical Flow. `TERM_CRITERIA_COUNT` shows The max number of iterations(10 below) and `TERM_CRITERIA_EPS` represents the epsilon (0.03 below). More iterations means a more exhaustive search, and a smaller epsilon finishes earlier. These are primarily useful in exchanging speed vs accuracy of tracking, but mainly stay the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f43cdcc-1f26-4b78-9a07-164286e03449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for lucas kanade optical flow\n",
    "lk_params = {\n",
    "    'winSize': (200, 200),\n",
    "    'maxLevel': 2,\n",
    "    'criteria': (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16e04261-a6d0-434c-bbc6-93e9749c9c7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Capture the video\n",
    "cap = cv2.VideoCapture()\n",
    "cap.open(\"/dev/v4l/by-id/usb-Sonix_Technology_Co.__Ltd._USB_2.0_Camera-video-index0\")\n",
    "\n",
    "# Grab the very first frame of the stream\n",
    "ret, prev_frame = cap.read()\n",
    "\n",
    "# Grab a grayscale image (We will refer to this as the previous frame)\n",
    "prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Grabbing the corners\n",
    "prevPts = cv2.goodFeaturesToTrack(prev_gray, mask = None, **corner_track_params)\n",
    "\n",
    "# Create a matching mask of the previous frame for drawing on later\n",
    "mask = np.zeros_like(prev_frame)\n",
    "\n",
    "\n",
    "while True:\n",
    "    \n",
    "    # Grab current frame\n",
    "    ret,frame = cap.read()\n",
    "    \n",
    "    # Grab gray scale\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Calculate the Optical Flow on the Gray Scale Frame\n",
    "    nextPts, status, err = cv2.calcOpticalFlowPyrLK(prev_gray, frame_gray, prevPts, None, **lk_params)\n",
    "    \n",
    "    # Using the returned status array (the status output)\n",
    "    # status output status vector (of unsigned chars); each element of the vector is set to 1 if\n",
    "    # the flow for the corresponding features has been found, otherwise, it is set to 0.\n",
    "    good_new = nextPts[status==1]\n",
    "    good_prev = prevPts[status==1]\n",
    "    \n",
    "    # Use ravel to get points to draw lines and circles\n",
    "    for i, (new,prev) in enumerate(zip(good_new, good_prev)):\n",
    "        \n",
    "        x_new, y_new = new.ravel()\n",
    "        x_prev, y_prev = prev.ravel()\n",
    "\n",
    "        x_new,y_new = int(x_new), int(y_new)\n",
    "        x_prev,y_prev = int(x_prev), int(y_prev)\n",
    "        \n",
    "        \n",
    "        # Lines will be drawn using the mask created from the first frame\n",
    "        mask = cv2.line(mask, (x_new,y_new),(x_prev,y_prev), (0,255,0), 3)\n",
    "        \n",
    "        # Draw red circles at corner points\n",
    "        frame = cv2.circle(frame,(x_new,y_new),8,(0,0,255),-1)\n",
    "    \n",
    "    # Display the image along with the mask we drew the line on.\n",
    "    img = cv2.add(frame,mask)\n",
    "    cv2.imshow('frame',img)\n",
    "    \n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "   \n",
    "    # Now update the previous frame and previous points\n",
    "    prev_gray = frame_gray.copy()\n",
    "    prevPts = good_new.reshape(-1,1,2)\n",
    "    \n",
    "    \n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c39901-b724-425d-a407-9b9812a89b75",
   "metadata": {},
   "source": [
    ">**Practical Note:**\n",
    "<br>- If you move really fast, it may loose some of the keypoints.\n",
    "<br>- If the keypoints are disappeared, this optical flow will not be albe to track them any further\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
