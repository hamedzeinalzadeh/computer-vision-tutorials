{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f85a3e8-c887-49db-9e3c-c2e9a37ba395",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c96b5853-4064-43ed-9d47-1f4a182e728b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first find features\n",
    "# for exampld return a list of features\n",
    "# features = [(x1, y1), (x2, y2), ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f553d5a4-0006-4b22-99c7-47dd5d1be539",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@20495.396] global /croot/opencv-suite_1676452025216/work/opencv_contrib-4.6.0/modules/xfeatures2d/misc/python/shadow_sift.hpp (13) SIFT_create DEPRECATED: cv.xfeatures2d.SIFT_create() is deprecated due SIFT tranfer to the main repository. https://github.com/opencv/opencv/issues/16736\n"
     ]
    }
   ],
   "source": [
    "sift = cv2.xfeatures2d.SIFT_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1dedbf7f-4adc-485f-8573-5efebafc0f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@206.568] global /croot/opencv-suite_1676452025216/work/modules/videoio/src/cap_gstreamer.cpp (862) isPipelinePlaying OpenCV | GStreamer warning: GStreamer: pipeline have not been created\n",
      "[ WARN:0@206.857] global /croot/opencv-suite_1676452025216/work/modules/videoio/src/cap_gstreamer.cpp (862) isPipelinePlaying OpenCV | GStreamer warning: GStreamer: pipeline have not been created\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load your calibration data\n",
    "calibration_data = {\n",
    "    \"left_camera_matrix\": np.array([\n",
    "        [719.4914360561231, 0.0, 294.6618243944737],\n",
    "        [0.0, 724.316856107926, 236.6674709593225],\n",
    "        [0.0, 0.0, 1.0]\n",
    "    ]),\n",
    "    \"R\": np.array([\n",
    "        [0.998744266362166, -0.02468958215792122, -0.04359260191323893],\n",
    "        [0.02271587159598623, 0.9987194131506791, -0.04520534231258201],\n",
    "        [0.044652878813504625, 0.044158332496034194, 0.9980261329668858]\n",
    "    ]),\n",
    "    \"T\": np.array([\n",
    "        [-88.0686467506865],\n",
    "        [-5.999330484193485],\n",
    "        [61.08623078827746]\n",
    "    ])\n",
    "}\n",
    "\n",
    "def draw_axes(img, corner, imgpts):\n",
    "    corner = tuple(corner.ravel().astype(int))\n",
    "    img = cv2.line(img, corner, tuple(imgpts[0].ravel().astype(int)), (255,0,0), 5)\n",
    "    img = cv2.line(img, corner, tuple(imgpts[1].ravel().astype(int)), (0,255,0), 5)\n",
    "    img = cv2.line(img, corner, tuple(imgpts[2].ravel().astype(int)), (0,0,255), 5)\n",
    "    return img\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    cam1_id = 4 # Update with your camera ID\n",
    "    cam2_id = 1  # Update with your camera ID\n",
    "    cap_left, cap_right = cv2.VideoCapture(cam1_id), cv2.VideoCapture(cam2_id)\n",
    "    axis = np.float32([[3,0,0], [0,3,0], [0,0,-3]]).reshape(-1,3)\n",
    "\n",
    "    while True:\n",
    "        ret_left, frame_left = cap_left.read()\n",
    "        ret_right, frame_right = cap_right.read()\n",
    "        if ret_left and ret_right:\n",
    "            # Define the model points of the 3D axes you want to project in the image\n",
    "            # Drawing the axes on the left camera image\n",
    "            R_vect, _ = cv2.Rodrigues(calibration_data['R'])  # Convert rotation matrix to rotation vector\n",
    "            T_vect = calibration_data['T']\n",
    "            imgpts, _ = cv2.projectPoints(axis, R_vect, T_vect, calibration_data['left_camera_matrix'], distCoeffs=None)\n",
    "\n",
    "            frame_left_with_axes = draw_axes(frame_left, np.float32([calibration_data['left_camera_matrix'][:2,2]]), imgpts)\n",
    "            cv2.imshow('Stereo Camera - Left', frame_left_with_axes)\n",
    "            cv2.imshow('Stereo Camera - Right', frame_right)\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            print(\"Failed to capture images\")\n",
    "            break\n",
    "\n",
    "    cap_left.release()\n",
    "    cap_right.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5000ce12-5b06-4b5c-b855-5efac6ab79f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac765d70-87d7-47aa-9673-32e9eb5ad32b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(python:49425): GStreamer-CRITICAL **: 08:44:28.753: gst_element_make_from_uri: assertion 'gst_uri_is_valid (uri)' failed\n",
      "[ WARN:0@0.104] global /croot/opencv-suite_1676452025216/work/modules/videoio/src/cap_gstreamer.cpp (1127) open OpenCV | GStreamer warning: Error opening bin: no source element for URI \"/dev/video0\"\n",
      "[ WARN:0@0.104] global /croot/opencv-suite_1676452025216/work/modules/videoio/src/cap_gstreamer.cpp (862) isPipelinePlaying OpenCV | GStreamer warning: GStreamer: pipeline have not been created\n",
      "[ WARN:0@0.253] global /croot/opencv-suite_1676452025216/work/modules/videoio/src/cap_gstreamer.cpp (2401) handleMessage OpenCV | GStreamer warning: Embedded video playback halted; module source reported: Could not read from resource.\n",
      "[ WARN:0@0.254] global /croot/opencv-suite_1676452025216/work/modules/videoio/src/cap_gstreamer.cpp (1356) open OpenCV | GStreamer warning: unable to start pipeline\n",
      "[ WARN:0@0.254] global /croot/opencv-suite_1676452025216/work/modules/videoio/src/cap_gstreamer.cpp (862) isPipelinePlaying OpenCV | GStreamer warning: GStreamer: pipeline have not been created\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Could not open one or more cameras.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring XDG_SESSION_TYPE=wayland on Gnome. Use QT_QPA_PLATFORM=wayland to run on Wayland anyway.\n",
      "libGL error: MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "libGL error: failed to load driver: iris\n",
      "libGL error: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "libGL error: failed to load driver: swrast\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Could not read frame from one or more cameras.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Replace 'address_left' and 'address_right' with the addresses of your left and right cameras\n",
    "camera_address_left = '/dev/video0'\n",
    "camera_address_right = '/dev/video1'\n",
    "\n",
    "# Create VideoCapture objects for both cameras\n",
    "cap_left = cv2.VideoCapture(camera_address_left)\n",
    "cap_right = cv2.VideoCapture(camera_address_right)\n",
    "\n",
    "# Check if the cameras were opened successfully\n",
    "if not cap_left.isOpened() or not cap_right.isOpened():\n",
    "    print(\"Error: Could not open one or more cameras.\")\n",
    "    exit()\n",
    "\n",
    "# Create a window to display the stereo feed\n",
    "cv2.namedWindow('Stereo Camera Setup', cv2.WINDOW_NORMAL)\n",
    "\n",
    "# Capture and display frames from both cameras simultaneously\n",
    "while True:\n",
    "    # Capture frames from both cameras\n",
    "    ret_left, frame_left = cap_left.read()\n",
    "    ret_right, frame_right = cap_right.read()\n",
    "\n",
    "    # Check if frames were captured successfully\n",
    "    if not ret_left or not ret_right:\n",
    "        print(\"Error: Could not read frame from one or more cameras.\")\n",
    "        break\n",
    "\n",
    "    # Resize frames to fit side by side\n",
    "    frame_left_resized = cv2.resize(frame_left, (640, 480))\n",
    "    frame_right_resized = cv2.resize(frame_right, (640, 480))\n",
    "\n",
    "    # Concatenate frames horizontally\n",
    "    stereo_feed = cv2.hconcat([frame_left_resized, frame_right_resized])\n",
    "\n",
    "    # Display stereo feed\n",
    "    cv2.imshow('Stereo Camera Setup', stereo_feed)\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the VideoCapture objects and close any OpenCV windows\n",
    "cap_left.release()\n",
    "cap_right.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eccee682-2072-4b60-a6d1-86a1ac00f6d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@190.437] global /croot/opencv-suite_1676452025216/work/modules/videoio/src/cap_gstreamer.cpp (862) isPipelinePlaying OpenCV | GStreamer warning: GStreamer: pipeline have not been created\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Connects to your computer's default camera\n",
    "#cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Capture the video from the specific camera connected to your system\n",
    "cap = cv2.VideoCapture(4)\n",
    "#cap.open(\"/dev/v4l/by-path/pci-0000:00:14.0-usb-0:5:1.0-video-index1\")\n",
    "\n",
    "\n",
    "# Automatically grab width and height from video feed\n",
    "# (returns float which we need to convert to integer for later on!)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "ret, frame = cap.read()\n",
    "\n",
    "while True:\n",
    "    \n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Operations on the frame come here\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame',gray)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture and destroy the windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490a2957-05cd-4fd3-9e63-46904eef0756",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
