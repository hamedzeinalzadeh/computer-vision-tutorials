{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57c58412-eadf-4e03-986c-f00f93acb48b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@598.140] global /croot/opencv-suite_1676452025216/work/modules/videoio/src/cap_gstreamer.cpp (862) isPipelinePlaying OpenCV | GStreamer warning: GStreamer: pipeline have not been created\n",
      "\u001b[32m2024-02-14 00:32:49.381\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcapture_calibration_images\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mCaptured ./calibration_images/calib_image_0.png\u001b[0m\n",
      "\u001b[32m2024-02-14 00:32:50.600\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcapture_calibration_images\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mCaptured ./calibration_images/calib_image_1.png\u001b[0m\n",
      "\u001b[32m2024-02-14 00:32:51.565\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcapture_calibration_images\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mCaptured ./calibration_images/calib_image_2.png\u001b[0m\n",
      "\u001b[32m2024-02-14 00:32:52.688\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcapture_calibration_images\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mCaptured ./calibration_images/calib_image_3.png\u001b[0m\n",
      "\u001b[32m2024-02-14 00:32:54.483\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcapture_calibration_images\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mCaptured ./calibration_images/calib_image_4.png\u001b[0m\n",
      "\u001b[32m2024-02-14 00:32:55.912\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcapture_calibration_images\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mCaptured ./calibration_images/calib_image_5.png\u001b[0m\n",
      "\u001b[32m2024-02-14 00:32:58.694\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcapture_calibration_images\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mCaptured ./calibration_images/calib_image_6.png\u001b[0m\n",
      "\u001b[32m2024-02-14 00:33:00.802\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcapture_calibration_images\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mCaptured ./calibration_images/calib_image_7.png\u001b[0m\n",
      "\u001b[32m2024-02-14 00:33:03.007\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcapture_calibration_images\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mCaptured ./calibration_images/calib_image_8.png\u001b[0m\n",
      "\u001b[32m2024-02-14 00:33:05.188\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcapture_calibration_images\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mCaptured ./calibration_images/calib_image_9.png\u001b[0m\n",
      "\u001b[32m2024-02-14 00:33:06.494\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcapture_calibration_images\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mCaptured ./calibration_images/calib_image_10.png\u001b[0m\n",
      "\u001b[32m2024-02-14 00:33:07.430\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcapture_calibration_images\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mCaptured ./calibration_images/calib_image_11.png\u001b[0m\n",
      "\u001b[32m2024-02-14 00:33:08.503\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcapture_calibration_images\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mCaptured ./calibration_images/calib_image_12.png\u001b[0m\n",
      "\u001b[32m2024-02-14 00:33:10.308\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcapture_calibration_images\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mCaptured ./calibration_images/calib_image_13.png\u001b[0m\n",
      "\u001b[32m2024-02-14 00:33:11.622\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcapture_calibration_images\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mCaptured ./calibration_images/calib_image_14.png\u001b[0m\n",
      "\u001b[32m2024-02-14 00:33:14.428\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcapture_calibration_images\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mCaptured ./calibration_images/calib_image_15.png\u001b[0m\n",
      "\u001b[32m2024-02-14 00:33:19.374\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcapture_calibration_images\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mCaptured ./calibration_images/calib_image_16.png\u001b[0m\n",
      "\u001b[32m2024-02-14 00:33:21.221\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcapture_calibration_images\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mCaptured ./calibration_images/calib_image_17.png\u001b[0m\n",
      "\u001b[32m2024-02-14 00:33:25.070\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcapture_calibration_images\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mCaptured ./calibration_images/calib_image_18.png\u001b[0m\n",
      "\u001b[32m2024-02-14 00:33:28.620\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcapture_calibration_images\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mCaptured ./calibration_images/calib_image_19.png\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Focal length in pixels: fx = 842.0157403005035, fy = 845.4201802650275\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from loguru import logger\n",
    "from tqdm import tqdm\n",
    "\n",
    "def capture_calibration_images(save_dir, num_images=20):\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        logger.error(\"Cannot open camera\")\n",
    "        exit()\n",
    "    captured = 0\n",
    "    while captured < num_images:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            logger.error(\"Failed to grab frame\")\n",
    "            break\n",
    "        cv2.imshow('Frame', frame)\n",
    "        k = cv2.waitKey(1)\n",
    "        if k == ord('c'):  # Press 'c' to capture and save the image\n",
    "            img_name = os.path.join(save_dir, f\"calib_image_{captured}.png\")\n",
    "            cv2.imwrite(img_name, frame)\n",
    "            logger.info(f\"Captured {img_name}\")\n",
    "            captured += 1\n",
    "        elif k == 27:  # Press 'ESC' to exit\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def find_chessboard_corners(images, chessboard_size, criteria):\n",
    "    objp = np.zeros((chessboard_size[0]*chessboard_size[1], 3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:chessboard_size[0], 0:chessboard_size[1]].T.reshape(-1,2)\n",
    "\n",
    "    objpoints = []  # 3d point in real world space\n",
    "    imgpoints = []  # 2d points in image plane.\n",
    "\n",
    "    for fname in images:\n",
    "        img = cv2.imread(fname)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        ret, corners = cv2.findChessboardCorners(gray, chessboard_size, None)\n",
    "        if ret == True:\n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners)\n",
    "    return objpoints, imgpoints\n",
    "\n",
    "def calibrate_camera(objpoints, imgpoints, frameSize):\n",
    "    ret, cameraMatrix, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, frameSize, None, None)\n",
    "    return cameraMatrix\n",
    "\n",
    "def main():\n",
    "    chessboard_size = (5, 7)  # Define the number of inner corners per a chessboard row and column\n",
    "    frameSize = (640, 480)\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "    save_dir = './calibration_images'\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    # Capture images for calibration\n",
    "    capture_calibration_images(save_dir, num_images=20)\n",
    "\n",
    "    images = [os.path.join(save_dir, f) for f in os.listdir(save_dir) if f.endswith('.png')]\n",
    "    objpoints, imgpoints = find_chessboard_corners(images, chessboard_size, criteria)\n",
    "    cameraMatrix = calibrate_camera(objpoints, imgpoints, frameSize)\n",
    "\n",
    "    fx = cameraMatrix[0, 0]\n",
    "    fy = cameraMatrix[1, 1]\n",
    "    print(f\"Focal length in pixels: fx = {fx}, fy = {fy}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78b4b6b4-4664-4691-8bff-c1ce0244c501",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'monovideoodometery'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Ensure that you've correctly imported or defined MonoVideoOdometery elsewhere\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmonovideoodometery\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MonoVideoOdometery\n\u001b[1;32m     10\u001b[0m focal \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4.0\u001b[39m\n\u001b[1;32m     11\u001b[0m pp \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'monovideoodometery'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Ensure that you've correctly imported or defined MonoVideoOdometery elsewhere\n",
    "from monovideoodometery import MonoVideoOdometery\n",
    "\n",
    "focal = 4.0\n",
    "pp = (0, 0)\n",
    "\n",
    "# Parameters for lucas kanade optical flow\n",
    "lk_params = dict(winSize=(21, 21),\n",
    "                 criteria=(cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, 30, 0.01))\n",
    "\n",
    "# Initialize video capture from the USB camera\n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "# Check if the camera opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video capture.\")\n",
    "    exit()\n",
    "\n",
    "# Adjust the constructor based on your class definition\n",
    "vo = MonoVideoOdometery(focal, pp, lk_params)\n",
    "traj = np.zeros(shape=(600, 800, 3))\n",
    "\n",
    "while True:\n",
    "    # Read frame from camera\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to grab frame.\")\n",
    "        break\n",
    "\n",
    "    # Assuming you have a method to update the frame in your MonoVideoOdometery class\n",
    "    vo.set_current_frame(frame)\n",
    "\n",
    "    cv.imshow('frame', frame)\n",
    "    k = cv.waitKey(1)\n",
    "    if k == 27:  # ESC key to exit\n",
    "        break\n",
    "\n",
    "    vo.process_frame()\n",
    "\n",
    "    # Depending on how your MonoVideoOdometery class works, you might need to adjust this part\n",
    "    # For example, if it's designed to work with a sequence of images loaded from disk,\n",
    "    # you'll need to ensure it can handle continuous frames from the video stream.\n",
    "\n",
    "    # Update trajectory visualization as needed\n",
    "    # Note: Without ground truth poses, some parts related to true coordinates must be removed or modified\n",
    "\n",
    "# Cleanup\n",
    "cap.release()\n",
    "cv.destroyAllWindows()\n",
    "\n",
    "\n",
    "# img_path = 'C:\\\\Users\\\\Ali\\\\Desktop\\\\Projects\\\\SLAM\\\\videos\\\\data_odometry_gray\\\\dataset\\\\sequences\\\\00\\\\image_0\\\\'\n",
    "# pose_path = 'C:\\\\Users\\\\Ali\\\\Desktop\\\\Projects\\\\SLAM\\\\videos\\\\data_odometry_poses\\\\dataset\\\\poses\\\\00.txt'\n",
    "\n",
    "# focal = 718.8560\n",
    "# pp = (607.1928, 185.2157)\n",
    "# R_total = np.zeros((3, 3))\n",
    "# t_total = np.empty(shape=(3, 1))\n",
    "\n",
    "# # Parameters for lucas kanade optical flow\n",
    "# lk_params = dict( winSize  = (21,21),\n",
    "#                   criteria = (cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, 30, 0.01))\n",
    "\n",
    "\n",
    "# # Create some random colors\n",
    "# color = np.random.randint(0,255,(5000,3))\n",
    "\n",
    "# vo = MonoVideoOdometery(img_path, pose_path, focal, pp, lk_params)\n",
    "# traj = np.zeros(shape=(600, 800, 3))\n",
    "\n",
    "# # mask = np.zeros_like(vo.current_frame)\n",
    "# # flag = False\n",
    "# while(vo.hasNextFrame()):\n",
    "\n",
    "#     frame = vo.current_frame\n",
    "\n",
    "#     # for i, (new,old) in enumerate(zip(vo.good_new, vo.good_old)):\n",
    "#     #     a,b = new.ravel()\n",
    "#     #     c,d = old.ravel()\n",
    "\n",
    "#     #     if np.linalg.norm(new - old) < 10:\n",
    "#     #         if flag:\n",
    "#     #             mask = cv.line(mask, (a,b),(c,d), color[i].tolist(), 2)\n",
    "#     #             frame = cv.circle(frame,(a,b),5,color[i].tolist(),-1)\n",
    "\n",
    "\n",
    "#     # cv.add(frame, mask)\n",
    "#     cv.imshow('frame', frame)\n",
    "#     k = cv.waitKey(1)\n",
    "#     if k == 27:\n",
    "#         break\n",
    "\n",
    "#     if k == 121:\n",
    "#         flag = not flag\n",
    "#         toggle_out = lambda flag: \"On\" if flag else \"Off\"\n",
    "#         print(\"Flow lines turned \", toggle_out(flag))\n",
    "#         mask = np.zeros_like(vo.old_frame)\n",
    "#         mask = np.zeros_like(vo.current_frame)\n",
    "\n",
    "#     vo.process_frame()\n",
    "\n",
    "#     print(vo.get_mono_coordinates())\n",
    "\n",
    "#     mono_coord = vo.get_mono_coordinates()\n",
    "#     true_coord = vo.get_true_coordinates()\n",
    "\n",
    "#     print(\"MSE Error: \", np.linalg.norm(mono_coord - true_coord))\n",
    "#     print(\"x: {}, y: {}, z: {}\".format(*[str(pt) for pt in mono_coord]))\n",
    "#     print(\"true_x: {}, true_y: {}, true_z: {}\".format(*[str(pt) for pt in true_coord]))\n",
    "\n",
    "#     draw_x, draw_y, draw_z = [int(round(x)) for x in mono_coord]\n",
    "#     true_x, true_y, true_z = [int(round(x)) for x in true_coord]\n",
    "\n",
    "#     traj = cv.circle(traj, (true_x + 400, true_z + 100), 1, list((0, 0, 255)), 4)\n",
    "#     traj = cv.circle(traj, (draw_x + 400, draw_z + 100), 1, list((0, 255, 0)), 4)\n",
    "\n",
    "#     cv.putText(traj, 'Actual Position:', (140, 90), cv.FONT_HERSHEY_SIMPLEX, 0.5,(255,255,255), 1)\n",
    "#     cv.putText(traj, 'Red', (270, 90), cv.FONT_HERSHEY_SIMPLEX, 0.5,(0, 0, 255), 1)\n",
    "#     cv.putText(traj, 'Estimated Odometry Position:', (30, 120), cv.FONT_HERSHEY_SIMPLEX, 0.5,(255,255,255), 1)\n",
    "#     cv.putText(traj, 'Green', (270, 120), cv.FONT_HERSHEY_SIMPLEX, 0.5,(0, 255, 0), 1)\n",
    "\n",
    "#     cv.imshow('trajectory', traj)\n",
    "# cv.imwrite(\"./images/trajectory.png\", traj)\n",
    "\n",
    "# cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b04a38f-070c-42f2-b522-edb7d7460a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera matrix (focal length and principal point):\n",
      "[[833.23839296   0.         306.58408037]\n",
      " [  0.         836.22628495 248.90965481]\n",
      " [  0.           0.           1.        ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "\n",
    "# Termination criteria for the corner sub-pixel optimization process\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "# Prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "# Adjust the following variables based on your chessboard dimensions\n",
    "# Chessboard dimensions (number of inner corners per chessboard row and column)\n",
    "chessboard_size = (5, 7)\n",
    "objp = np.zeros((chessboard_size[0] * chessboard_size[1], 3), np.float32)\n",
    "objp[:, :2] = np.mgrid[0:chessboard_size[0],\n",
    "                       0:chessboard_size[1]].T.reshape(-1, 2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = []  # 3d point in real world space\n",
    "imgpoints = []  # 2d points in image plane.\n",
    "\n",
    "# Change the path to where your calibration images are stored\n",
    "images = glob.glob('Monocular-Video-Odometery/calibration_images/*.png')\n",
    "\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chess board corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, chessboard_size, None)\n",
    "\n",
    "    # If found, add object points, image points (after refining them)\n",
    "    if ret:\n",
    "        objpoints.append(objp)\n",
    "\n",
    "        corners2 = cv2.cornerSubPix(\n",
    "            gray, corners, (11, 11), (-1, -1), criteria)\n",
    "        imgpoints.append(corners2)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        cv2.drawChessboardCorners(img, chessboard_size, corners2, ret)\n",
    "        \n",
    "        cv2.imshow('img', img)\n",
    "        cv2.waitKey(500)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Calibrate the camera\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(\n",
    "    objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "\n",
    "print(\"Camera matrix (focal length and principal point):\")\n",
    "print(mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45640fdb-74b3-4f0a-8007-6f1dd414770b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b04781e-ce82-4a0b-ada0-bb7eeb98c4e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[833.23839296,   0.        , 306.58408037],\n",
       "       [  0.        , 836.22628495, 248.90965481],\n",
       "       [  0.        ,   0.        ,   1.        ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6bfead81-b522-4c98-86cd-0e4977ba2f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtx_ = np.array([[833.23839296,   0.        , 306.58408037],\n",
    "       [  0.        , 836.22628495, 248.90965481],\n",
    "       [  0.        ,   0.        ,   1.        ]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d8ed939-2b7f-4464-9070-65e62a25c07d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "834.732338955"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(mtx_[0,0]+mtx_[1,1])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5fbc1ed5-d32f-495a-9f4d-aa71827f2505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(306.5840803736371, 248.90965481162658)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(mtx[0, 2], mtx[1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657d19ed-4c29-4de6-b21a-c1865d0c2caa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
